{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n#Adding libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-12T09:12:50.114088Z","iopub.execute_input":"2022-02-12T09:12:50.115091Z","iopub.status.idle":"2022-02-12T09:12:50.127759Z","shell.execute_reply.started":"2022-02-12T09:12:50.115024Z","shell.execute_reply":"2022-02-12T09:12:50.126924Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"**Approach:**\nFirst step was to import all the required libraries and also the train and test files into the notebook. By inspecting the data, we found out that there does not exits null values or data redundancies in train and test data set therfore removing the requirement for data cleaning/data imputation. Our next step was to visualize the training dataset which resulted in our finding that content made for students will be very much beneficial to any video platforms since the engagement score of students was greatest of the three. Next, since there exist 2 categorical features in our training dataset, i gave them tags using label encoding. Next step was seperating the train data into training and validation data where we split them into 3:1 ratio. Next, we imported different ML models and assessed them on the basis of r2_score as evaluation metric. We found that XGB regressor was the best among all the models chosen in order to predict engagement score. Last but not the least, we submitted our data predicted using XGB regressor model keeping only the postive engagement scores in the sheet and removing the negative score if any.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\n\nimport warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:50.129655Z","iopub.execute_input":"2022-02-12T09:12:50.130052Z","iopub.status.idle":"2022-02-12T09:12:50.136778Z","shell.execute_reply.started":"2022-02-12T09:12:50.130018Z","shell.execute_reply":"2022-02-12T09:12:50.136105Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"**1) Reading dataset**","metadata":{}},{"cell_type":"code","source":"def load_data():\n    # Read data\n    data_dir = Path(\"../input/jobathon-february-2022\")\n    \n    df_train = pd.read_csv(data_dir / \"train_0OECtn8.csv\", index_col=\"row_id\")\n    df_test = pd.read_csv(data_dir / \"test_1zqHu22.csv\", index_col=\"row_id\")\n\n    return df_train, df_test\n","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:50.138164Z","iopub.execute_input":"2022-02-12T09:12:50.138606Z","iopub.status.idle":"2022-02-12T09:12:50.151786Z","shell.execute_reply.started":"2022-02-12T09:12:50.138567Z","shell.execute_reply":"2022-02-12T09:12:50.150682Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/jobathon-february-2022/train.csv') \ntest = pd.read_csv('../input/jobathon-february-2022/test.csv') \ntrain.shape, test.shape\n","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:50.153445Z","iopub.execute_input":"2022-02-12T09:12:50.154218Z","iopub.status.idle":"2022-02-12T09:12:50.253734Z","shell.execute_reply.started":"2022-02-12T09:12:50.154173Z","shell.execute_reply":"2022-02-12T09:12:50.252740Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"**2) Data Inspection**","metadata":{}},{"cell_type":"code","source":"#Inspecting Data by checking ratio of null values for train dataset\n\ntrain.isnull().sum()/train.shape[0] *100\n","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:50.254949Z","iopub.execute_input":"2022-02-12T09:12:50.255222Z","iopub.status.idle":"2022-02-12T09:12:50.274346Z","shell.execute_reply.started":"2022-02-12T09:12:50.255192Z","shell.execute_reply":"2022-02-12T09:12:50.273445Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"We can see above that no data is null in the train dataset.  ","metadata":{}},{"cell_type":"code","source":"#Inspecting Data by checking null values ratio of null values for test \n\ntest.isnull().sum()/test.shape[0] *100","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:50.275562Z","iopub.execute_input":"2022-02-12T09:12:50.275836Z","iopub.status.idle":"2022-02-12T09:12:50.287200Z","shell.execute_reply.started":"2022-02-12T09:12:50.275810Z","shell.execute_reply":"2022-02-12T09:12:50.286234Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"We can see above that no data is null in the test dataset.  ","metadata":{}},{"cell_type":"code","source":"#Determining number of categorical and numerical features in the train dataset. \n#categorical features\ncategorical = train.select_dtypes(include =[np.object])\nprint(\"Categorical Features present in Train Set:\",categorical.shape[1])\n\n#numerical features\nnumerical= train.select_dtypes(include =[np.float64,np.int64])\nprint(\"Numerical Features present in Train Set:\",numerical.shape[1])","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:50.298377Z","iopub.execute_input":"2022-02-12T09:12:50.299090Z","iopub.status.idle":"2022-02-12T09:12:50.311844Z","shell.execute_reply.started":"2022-02-12T09:12:50.299027Z","shell.execute_reply":"2022-02-12T09:12:50.310879Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"#Determining number of categorical and numerical features in the test dataset. \n#categorical features\ncategorical = test.select_dtypes(include =[np.object])\nprint(\"Categorical Features present in test Set:\",categorical.shape[1])\n\n#numerical features\nnumerical= test.select_dtypes(include =[np.float64,np.int64])\nprint(\"Numerical Features present in test Set:\",numerical.shape[1])","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:50.313774Z","iopub.execute_input":"2022-02-12T09:12:50.314414Z","iopub.status.idle":"2022-02-12T09:12:50.325040Z","shell.execute_reply.started":"2022-02-12T09:12:50.314379Z","shell.execute_reply":"2022-02-12T09:12:50.324124Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"***3) Data Cleaning ***\n","metadata":{}},{"cell_type":"code","source":"#Since no null values in train and test dataset, no data cleaning is required ","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:50.326669Z","iopub.execute_input":"2022-02-12T09:12:50.327167Z","iopub.status.idle":"2022-02-12T09:12:50.336828Z","shell.execute_reply.started":"2022-02-12T09:12:50.327124Z","shell.execute_reply":"2022-02-12T09:12:50.336049Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"**4) Checking Data Redundancies**","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:50.338109Z","iopub.execute_input":"2022-02-12T09:12:50.338991Z","iopub.status.idle":"2022-02-12T09:12:50.358950Z","shell.execute_reply.started":"2022-02-12T09:12:50.338945Z","shell.execute_reply":"2022-02-12T09:12:50.358112Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:50.361498Z","iopub.execute_input":"2022-02-12T09:12:50.361769Z","iopub.status.idle":"2022-02-12T09:12:50.373229Z","shell.execute_reply.started":"2022-02-12T09:12:50.361736Z","shell.execute_reply":"2022-02-12T09:12:50.372293Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"train['profession'].value_counts()   # we can see that there is no redundancies in the profession data. Therefore no need to fix this data.  \n                                    \n","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:50.374760Z","iopub.execute_input":"2022-02-12T09:12:50.375166Z","iopub.status.idle":"2022-02-12T09:12:50.392712Z","shell.execute_reply.started":"2022-02-12T09:12:50.375114Z","shell.execute_reply":"2022-02-12T09:12:50.391944Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"train['gender'].value_counts()  # we can see that there is no redundancies in the gender data. Therefore no need to fix this data. ","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:50.393852Z","iopub.execute_input":"2022-02-12T09:12:50.394081Z","iopub.status.idle":"2022-02-12T09:12:50.412520Z","shell.execute_reply.started":"2022-02-12T09:12:50.394033Z","shell.execute_reply":"2022-02-12T09:12:50.411448Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"**5) Data Visualization**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(25,7))\nsns.countplot('gender',data=train,palette='spring')","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:50.413728Z","iopub.execute_input":"2022-02-12T09:12:50.413942Z","iopub.status.idle":"2022-02-12T09:12:50.661895Z","shell.execute_reply.started":"2022-02-12T09:12:50.413915Z","shell.execute_reply":"2022-02-12T09:12:50.661253Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(25,7))\nsns.countplot('profession',data=train,palette='summer')","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:50.663079Z","iopub.execute_input":"2022-02-12T09:12:50.663457Z","iopub.status.idle":"2022-02-12T09:12:50.914092Z","shell.execute_reply.started":"2022-02-12T09:12:50.663426Z","shell.execute_reply":"2022-02-12T09:12:50.913356Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(25,7))\nsns.countplot('age',data=train,palette='twilight')","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:50.915317Z","iopub.execute_input":"2022-02-12T09:12:50.915641Z","iopub.status.idle":"2022-02-12T09:12:51.753241Z","shell.execute_reply.started":"2022-02-12T09:12:50.915613Z","shell.execute_reply":"2022-02-12T09:12:51.752252Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.barplot(y='profession',x='engagement_score',data=train,palette='flag')\n# We can see that the content made for students will be very much beneficial to any video platforms since the engagement score\n# of students if greatest of the three. ","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:51.754612Z","iopub.execute_input":"2022-02-12T09:12:51.754837Z","iopub.status.idle":"2022-02-12T09:12:52.985664Z","shell.execute_reply.started":"2022-02-12T09:12:51.754810Z","shell.execute_reply":"2022-02-12T09:12:52.984744Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"**7) Encoding Categorical Variables**\n","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:52.987633Z","iopub.execute_input":"2022-02-12T09:12:52.987952Z","iopub.status.idle":"2022-02-12T09:12:53.001475Z","shell.execute_reply.started":"2022-02-12T09:12:52.987909Z","shell.execute_reply":"2022-02-12T09:12:53.000610Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# Labelencoding\nle = LabelEncoder()\nvar_mod = train.select_dtypes(include='object').columns\nfor i in var_mod:\n    train[i] = le.fit_transform(train[i])\n    \nfor i in var_mod:\n    test[i] = le.fit_transform(test[i])","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:53.002683Z","iopub.execute_input":"2022-02-12T09:12:53.002923Z","iopub.status.idle":"2022-02-12T09:12:53.054506Z","shell.execute_reply.started":"2022-02-12T09:12:53.002895Z","shell.execute_reply":"2022-02-12T09:12:53.053586Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:53.057099Z","iopub.execute_input":"2022-02-12T09:12:53.057367Z","iopub.status.idle":"2022-02-12T09:12:53.066042Z","shell.execute_reply.started":"2022-02-12T09:12:53.057338Z","shell.execute_reply":"2022-02-12T09:12:53.065044Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"**8) Data Seperation**","metadata":{}},{"cell_type":"code","source":"#seperating feature and target variable \nX= train.drop(columns = ['engagement_score'], axis=1)\ny= train['engagement_score']","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:53.067481Z","iopub.execute_input":"2022-02-12T09:12:53.067932Z","iopub.status.idle":"2022-02-12T09:12:53.087125Z","shell.execute_reply.started":"2022-02-12T09:12:53.067900Z","shell.execute_reply":"2022-02-12T09:12:53.086029Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# Using 25% of data as validation set\nX_train,X_valid,y_train,y_valid = train_test_split(X,y,test_size=0.25,random_state=22)","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:53.088816Z","iopub.execute_input":"2022-02-12T09:12:53.089604Z","iopub.status.idle":"2022-02-12T09:12:53.111461Z","shell.execute_reply.started":"2022-02-12T09:12:53.089552Z","shell.execute_reply":"2022-02-12T09:12:53.110752Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"**9) ML Models**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Ridge, Lasso, LinearRegression, BayesianRidge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom xgboost import XGBRegressor\n\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingClassifier\n# from sklearn.ensemble import RandomForestClassifier\n# from sklearn.pipeline import Pipeline\n# from sklearn.impute import SimpleImputer","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:53.112577Z","iopub.execute_input":"2022-02-12T09:12:53.113458Z","iopub.status.idle":"2022-02-12T09:12:53.118117Z","shell.execute_reply.started":"2022-02-12T09:12:53.113420Z","shell.execute_reply":"2022-02-12T09:12:53.117428Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# my_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()),\n#                               ('model', RandomForestRegressor(n_estimators=50,\n#                                                               random_state=0))\n#                              ])","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:53.120180Z","iopub.execute_input":"2022-02-12T09:12:53.120505Z","iopub.status.idle":"2022-02-12T09:12:53.130197Z","shell.execute_reply.started":"2022-02-12T09:12:53.120466Z","shell.execute_reply":"2022-02-12T09:12:53.129302Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import cross_val_score\n# from sklearn.metrics import r2_score\n\n# # Multiply by -1 since sklearn calculates *negative* MAE\n# scores = -1 * cross_val_score(my_pipeline, X, y,\n#                               cv=5,\n#                               scoring= 'r2')\n\n# print(\"score :\\n\", scores)","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:53.131712Z","iopub.execute_input":"2022-02-12T09:12:53.132550Z","iopub.status.idle":"2022-02-12T09:12:53.141239Z","shell.execute_reply.started":"2022-02-12T09:12:53.132502Z","shell.execute_reply":"2022-02-12T09:12:53.140450Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"technique = [LinearRegression(),  Ridge(), Lasso(),\n          KNeighborsRegressor(), DecisionTreeRegressor(), XGBRegressor(max_depth=10,\n    n_estimators=1000,\n    min_child_weight=0.5, \n    colsample_bytree=0.8, \n    subsample=0.8, \n    eta=0.1,\n    seed=42), RandomForestRegressor(), \n             BayesianRidge()    ]\n\n# technique = [RandomForestRegressor(random_state = 0) ]\n\ntechnique_names = ['Linear Regression', 'Ridge Regression', 'Lasso Regression',\n         'K Neighbors Regressor', 'Decision Tree Regressor', 'XGBRegressor' , \n                   'Random Forest Regressor', 'Bayesian Ridge'   ]\n# technique_names = ['Random Forest Regressor']\n\n\nr2_list = []","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:53.142370Z","iopub.execute_input":"2022-02-12T09:12:53.143101Z","iopub.status.idle":"2022-02-12T09:12:53.156008Z","shell.execute_reply.started":"2022-02-12T09:12:53.143043Z","shell.execute_reply":"2022-02-12T09:12:53.155328Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"r2_list","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:53.157342Z","iopub.execute_input":"2022-02-12T09:12:53.157685Z","iopub.status.idle":"2022-02-12T09:12:53.168010Z","shell.execute_reply.started":"2022-02-12T09:12:53.157658Z","shell.execute_reply":"2022-02-12T09:12:53.167283Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"***9.1 Evaluating models using R2 score ***\n","metadata":{}},{"cell_type":"code","source":"for name in technique:\n    model = name\n    model.fit(X_train,y_train)\n    y_pred = model.predict(X_valid)\n    score = metrics.r2_score(y_valid, y_pred )    #using r2 score as evaluation metric as defined in the problem\n    r2_list.append(score)\n   ","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:12:53.169383Z","iopub.execute_input":"2022-02-12T09:12:53.169736Z","iopub.status.idle":"2022-02-12T09:14:37.231218Z","shell.execute_reply.started":"2022-02-12T09:12:53.169707Z","shell.execute_reply":"2022-02-12T09:14:37.229721Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"r2_list","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:14:37.233033Z","iopub.execute_input":"2022-02-12T09:14:37.234881Z","iopub.status.idle":"2022-02-12T09:14:37.245708Z","shell.execute_reply.started":"2022-02-12T09:14:37.234821Z","shell.execute_reply":"2022-02-12T09:14:37.244660Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"evaluation = pd.DataFrame({'Model': technique_names,\n                           'score': r2_list})","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:14:37.247375Z","iopub.execute_input":"2022-02-12T09:14:37.247825Z","iopub.status.idle":"2022-02-12T09:14:37.260910Z","shell.execute_reply.started":"2022-02-12T09:14:37.247782Z","shell.execute_reply":"2022-02-12T09:14:37.259927Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"evaluation","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:14:37.262308Z","iopub.execute_input":"2022-02-12T09:14:37.263426Z","iopub.status.idle":"2022-02-12T09:14:37.281229Z","shell.execute_reply.started":"2022-02-12T09:14:37.263380Z","shell.execute_reply":"2022-02-12T09:14:37.280346Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"We can see that among all the models XGB Regressor has the best score. Therefore, chosing XGB Regressor model for predicting engagement score. ","metadata":{}},{"cell_type":"markdown","source":"**10) Submission of Prediction Data**","metadata":{}},{"cell_type":"code","source":"\nsubmission = pd.read_csv('../input/jobathon-february-2022/sample_submission.csv')\nmodel = XGBRegressor(max_depth=10,\n    n_estimators=1000,\n    min_child_weight=0.5, \n    colsample_bytree=0.8, \n    subsample=0.8, \n    eta=0.1,\n    seed=42) \nmodel.fit(X, y)\nfinal_predictions = model.predict(test)\nsubmission['engagement_score'] = final_predictions\n#only positive predictions for the target variable\nsubmission['engagement_score'] = submission['engagement_score'].apply(lambda x: 0 if x<0 else x)\nsubmission.to_csv('my_submission_XGB_4.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-12T09:14:37.282959Z","iopub.execute_input":"2022-02-12T09:14:37.283802Z","iopub.status.idle":"2022-02-12T09:15:58.203076Z","shell.execute_reply.started":"2022-02-12T09:14:37.283748Z","shell.execute_reply":"2022-02-12T09:15:58.202080Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"**Approach:** \nFirst step was to import all the required libraries and also the train and test files into the \nnotebook. By inspecting the data, we found out that there does not exits null values or data redundancies in train and test data set\ntherfore removing the requirement for data cleaning/data imputation. Our next step was to visualize the training dataset which resulted in our finding \nthat content made for students will be very much beneficial to any video platforms since the engagement score\nof students was greatest of the three. Next, since there exist 2 categorical features in our training dataset, i gave them tags using label encoding. \nNext step was seperating the train data into training and validation data where we split them into 3:1 ratio. Next, we imported different ML models and assessed them \non the basis of r2_score as evaluation metric. We found that XGB regressor was the best among all the models chosen in order to predict engagement score.\nLast but not the least, we submitted our  data predicted using XGB regressor\nmodel keeping only the postive engagement scores in the sheet and removing the negative score if any. ","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}